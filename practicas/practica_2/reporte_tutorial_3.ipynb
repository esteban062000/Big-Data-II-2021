{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Lab2_Notes.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T8XhAXdmGut"
      },
      "source": [
        "# How to Remove Outliers for Machine Learning\n",
        "\n",
        "Antes de modelar, es importante limpiar los datos para garantizar que las observaciones representan correctamente el problema. Algunas veces, se tienen datos extremos, muy lejos de los valores esperados o muy distintos de los demás valores. Estos puntos se llaman *outliers* y, a menudo, los modelos de *machine learning* pueden ser mejorados al comprender e incluso remover estos valores atípicos.\n",
        "\n",
        "## 1. What are Outliers?\n",
        "\n",
        "> *Definimos los outliers como muestras que están excepcionalmente lejos de la mayoría de los datos.*\n",
        "\n",
        "Pueden tener varias causas, por ejemplo:\n",
        "- Error al realizar la medición.\n",
        "- Corrupción de datos.\n",
        "- Es una observación real (e.g. Magnus Carlsen).\n",
        "\n",
        "No hay una manera precisa de definir e identificar *outliers*, pues dependen de las características específicas del dataset. Sin embargo, algunos métodos estadísticos pueden ayudar en esta tarea.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDztn08bmr_L"
      },
      "source": [
        "## 2. Test Dataset\n",
        "\n",
        "Se utilizará una población de 10 000 números aleatorios generados por una distribución Gaussiana. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FCBXqZm19cp",
        "outputId": "681266d9-6f77-4ce9-9c28-728684c79cfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generate gaussian data\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(10000) + 50\n",
        "# summarize\n",
        "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean=50.049 stdv=4.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGz4NxEqmugG"
      },
      "source": [
        "## 3. Standard Deviation Method\n",
        "\n",
        "Si se sabe que la distribución de los valores en la muestra es Gaussiana o casi Gaussiana, se puede usar la desviación estándar de la muestra para eliminar valores atípicos. Por ejemplo, se tienen estos rangos:\n",
        "\n",
        "- 1 desviación estándar de la media: 68% de los datos.\n",
        "- 2 desviaciones estándar de la media: 95% de los datos.\n",
        "- 3 desviaciones estándar de la media: 99.7% de los datos.\n",
        "\n",
        "Con pocos datos, se podría utilizar el segundo rango; con muchos datos, se puede utilizar el valor de 4 desviacione estándar (99.9).\n",
        "\n",
        "Por lo general, primero se estandarizan los datos. En el siguiente ejemplo, se eliminan los valores que estén alejados más de 3 desviaciones estándar de la media:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia3t0sR_3s2x",
        "outputId": "ff51680a-2b21-44f0-8def-dabaa4a917c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generate gaussian data\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(10000) + 50\n",
        "# summarize\n",
        "print('mean=%.3f stdv=%.3f' % (mean(data), std(data)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean=50.049 stdv=4.994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X4OPEUu3xeR"
      },
      "source": [
        "Luego, se pueden identificar los valores atípicos y eliminarlos. Al unir todo esto, se obtiene el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esgqOkhl30bW",
        "outputId": "d2642ee6-7d75-4cc8-da3b-cc7e470a346e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# identify outliers with standard deviation\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(10000) + 50\n",
        "# calculate summary statistics\n",
        "data_mean, data_std = mean(data), std(data)\n",
        "# identify outliers\n",
        "cut_off = data_std * 3\n",
        "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
        "# identify outliers\n",
        "outliers = [x for x in data if x < lower or x > upper]\n",
        "print('Identified outliers: %d' % len(outliers))\n",
        "# remove outliers\n",
        "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
        "print('Non-outlier observations: %d' % len(outliers_removed))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identified outliers: 29\n",
            "Non-outlier observations: 9971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT5h3EL14Ht4"
      },
      "source": [
        "Se pueden imaginar límites en dos dimensiones que definen una elipse si se tienen dos variables. Las muestras que aparezcan fuera de la elipse serán consideradas *outliers*. En tres dimensiones, sería un elipsoide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOVYMFMpmwni"
      },
      "source": [
        "## 4. Interquartile Range Method\n",
        "\n",
        "No todos los datos son lo suficientemente normales como para ser tratados como una distribución Gaussiana. Para estos casos, se puede utilizar el rango intercuartil (IQR), que identifica *outliers* que están por debajo del primer cuartil o por encima del tercer cuartil por un factor de *k*, donde *k* típicamente es 1.5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmILjK3S4r1R",
        "outputId": "59524819-882b-47d2-a8cd-e7e21f0602a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# identify outliers with interquartile range\n",
        "from numpy.random import seed\n",
        "from numpy.random import randn\n",
        "from numpy import percentile\n",
        "# seed the random number generator\n",
        "seed(1)\n",
        "# generate univariate observations\n",
        "data = 5 * randn(10000) + 50\n",
        "# calculate interquartile range\n",
        "q25, q75 = percentile(data, 25), percentile(data, 75)\n",
        "iqr = q75 - q25\n",
        "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))\n",
        "# calculate the outlier cutoff\n",
        "cut_off = iqr * 1.5\n",
        "lower, upper = q25 - cut_off, q75 + cut_off\n",
        "# identify outliers\n",
        "outliers = [x for x in data if x < lower or x > upper]\n",
        "print('Identified outliers: %d' % len(outliers))\n",
        "# remove outliers\n",
        "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
        "print('Non-outlier observations: %d' % len(outliers_removed))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentiles: 25th=46.685, 75th=53.359, IQR=6.674\n",
            "Identified outliers: 81\n",
            "Non-outlier observations: 9919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UuFeEGt41rs"
      },
      "source": [
        "Esta misma técnica se puede utilizar para datos en varias dimensiones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqO9c-DTmz7k"
      },
      "source": [
        "## 5. Automatic Outlier Detection\n",
        "\n",
        "En *machine learning*, una manera de detectar *outliers* es mediante el *one-class classification* (OCC). Involucra entrenar un modelo en los datos \"normales\" y predecir si un nuevo dato es normal o un *outlier*. \n",
        "\n",
        "Funciona muy bien en espacios con poca dimensionalidad, pero puede ser menos confiable conforme se agregan más dimensiones (conocido como *curse of dimensionality*).\n",
        "\n",
        "El *local outlier factor*, o LOF acortado, es una técnica que intenta aprovechar la idea de la cercanía de vecinos para detectar outliers. La librería *scikit-learn* provee una implementación de este enfoce en la clase **LocalOutlierFactor**. \n",
        "\n",
        "Para demostrar esto, se utilizará el conjunto de datos *Boston_Housing_Dataset.csv\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxsD71SC6nF8",
        "outputId": "d9233506-97aa-4976-fa2a-6e0478fa2111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load and summarize the dataset\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "# load the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = read_csv(url, header=None)\n",
        "# retrieve the array\n",
        "data = df.values\n",
        "# split into inpiut and output elements\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# summarize the shape of the dataset\n",
        "print(X.shape, y.shape)\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# summarize the shape of the train and test sets\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(506, 13) (506,)\n",
            "(339, 13) (167, 13) (339,) (167,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1p2vBdK9rjT"
      },
      "source": [
        "El código anterior carga el dataset, reporta el número de filas y columnas y luego el número de ejemplos asignados al dataset de entrenamiento y evaluación.\n",
        "\n",
        "En este caso, vamos a ajustar una regresión lineal, evaluar el rendimiento del modelo al entrenarlo con el conjunto de prueba y realizar predicciones, evaluándolas con el **mean absolute error** (MAE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q3PjsQb-ixe",
        "outputId": "28d129ca-5015-458d-8fa5-80a0babe19fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate model on the raw dataset\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# load the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = read_csv(url, header=None)\n",
        "# retrieve the array\n",
        "data = df.values\n",
        "# split into inpiut and output elements\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 3.417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OLnsNMs_pAX"
      },
      "source": [
        "Seguidamente, se puede intentar eliminar *outliers* del conjunto de datos. Se espera que los valores atípicos estén sesgando las predicciones del modelo, por lo que se podrían alcanzar mejores resultados al eliminarlos. \n",
        "\n",
        "Esto se puede alcanzar al definir el modelo **LocalOutlierFactor** y usarlo para realizar una predicción en el dataset, marcando cada fila como normal (1) o *outlier* (-1). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AIHxymGBS5x",
        "outputId": "989c988e-ff9f-43d4-ca88-e60810ebacc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate model on training dataset with outliers removed\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "# load the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
        "df = read_csv(url, header=None)\n",
        "# retrieve the array\n",
        "data = df.values\n",
        "# split into inpiut and output elements\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# summarize the shape of the training dataset\n",
        "print(X_train.shape, y_train.shape)\n",
        "# identify outliers in the training dataset\n",
        "lof = LocalOutlierFactor()\n",
        "yhat = lof.fit_predict(X_train)\n",
        "# select all rows that are not outliers\n",
        "mask = yhat != -1\n",
        "X_train, y_train = X_train[mask, :], y_train[mask]\n",
        "# summarize the shape of the updated training dataset\n",
        "print(X_train.shape, y_train.shape)\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# evaluate the model\n",
        "yhat = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "print('MAE: %.3f' % mae)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(339, 13) (339,)\n",
            "(305, 13) (305,)\n",
            "MAE: 3.356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRjzbw_bBchT"
      },
      "source": [
        "Como se puede apreciar, se eliminaron 34 filas con *outliers*, lo que permitió pasar de un error de 3.417 a un error de 3.356 ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ew4hEEDBnd5"
      },
      "source": [
        "## ¿Qué aprendí?\n",
        "Antes de este tutorial, solo conocía la regla IQR para detectar y eliminar *outliers*, por lo que aprender sobre distintos métodos y cuándo son útiles fue muy provechoso. En particular, considero que son herramientas importantes para tener en cuenta antes de trabajar con los datos y obtener una mejor preparación de ellos.\n",
        "\n",
        "En los siguientes modelos predictivos que deba realizar, serán de utilidad para detectar y eliminar *outliers*, lo que permitirá obtener mejores resultados en las predicciones, pues estarán más ajustadas a la gran mayoría de los datos recolectados.\n",
        "\n",
        "## Fuentes\n",
        "https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/"
      ]
    }
  ]
}