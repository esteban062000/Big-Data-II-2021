{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "Lab2_Notes.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLJkqsVwMBSH"
      },
      "source": [
        "# How to Use Feature Extraction on Tabular Data for Machine Learning\n",
        "\n",
        "> *Machine learning predictive modeling performance is only as good as your data, and your data is only as good as the way you prepare it for modeling.*\n",
        "\n",
        "La técnica más común para preparar los datos consiste en estudiar un *dataset* y revisar las expectativas de un algoritmo de *machine learning*, para luego elegir cuidadosamente las técnicas de preparación de datos más adecuadas. Esto es lento, caro y requiere mucha experiencia.\n",
        "\n",
        "Una alternativa es aplicar un conjunto de técnicas de preparación comunes en paralelo y combinar los resultados de todas las transformaciones en un solo *dataset*, para poder entrenar y evaluar un modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkuUO3G6NjzB"
      },
      "source": [
        "## 1. Feature Extraction Technique for Data Preparation\n",
        "\n",
        "Una técnica que busca el punto medio entre las descritas anteriormente, consiste en tratar la transformación de los datos de entrada como un procedimiento de **feature engineering** o **feature extraction**. Permite, entre otros beneficios, encontrar soluciones poco intuitivas a un costo computacional mucho más bajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v34C7qGtOEgO"
      },
      "source": [
        "### Dataset and Performance Baseline\n",
        "\n",
        "#### Wine Classification Dataset\n",
        "\n",
        "Se utilizará el *dataset Wine.csv*, que contiene 13 variables de entrada que describan la composición química de las muestras de vino, y requiere clasificar cada muestra en uno de tres tipos de vino posibles.\n",
        "\n",
        "El siguiente código carga el *dataset*, lo separa en columnas de entrada y salida, y luego condensa los arreglos de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRVKJcuoOg7Y",
        "outputId": "8bfac6f4-5273-4839-f592-05e3293f81f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# example of loading and summarizing the wine dataset\n",
        "from pandas import read_csv\n",
        "# define the location of the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
        "# load the dataset as a data frame\n",
        "df = read_csv(url, header=None)\n",
        "# retrieve the numpy array\n",
        "data = df.values\n",
        "# split the columns into input and output variables\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# summarize the shape of the loaded data\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 13) (178,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf7u32hPPw6T"
      },
      "source": [
        "Al correr el ejemplo, se puede ver que el *dataset* se cargó correctamente y que hay 179 filas de datos con 13 variables de entrada y 1 de salida. \n",
        "\n",
        "Seguidamente, se evalúa el modelo para determinar el *baseline performance*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2HLR0vaQPPs"
      },
      "source": [
        "#### Baseline Model Performance\n",
        "\n",
        "Se puede establecer un *baseline* en la tarea de clasificación de vino al evaluar un modelo en los datos *raw*. En este caso, se evaluará un modelo de regresión logística.\n",
        "\n",
        "Primero, se utiliza la librería *scikit-learn* para garantizar que las variables de entrada son numéricas y la variable de salida es una etiqueta, como lo espera la librería. Luego, se define el modelo; se evaluará usando el estándar de *repeated stratified k-fold cross validation* con *10 folds* y *3 repeats*.\n",
        "\n",
        "El rendimiento del modelo se evaluará utilizando la precisión en la clasificación. Al final, se reporta la media y la desviación estándar del rendimiento alcanzado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gk7bTwRvMr",
        "outputId": "e3c64b97-9369-4518-e3df-1aca41b4af44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# baseline model performance on the wine dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# load the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
        "df = read_csv(url, header=None)\n",
        "data = df.values\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# minimally prepare dataset\n",
        "X = X.astype('float')\n",
        "y = LabelEncoder().fit_transform(y.astype('str'))\n",
        "# define the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "# define the cross-validation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.955 (0.049)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o-sftCpP9sv"
      },
      "source": [
        "Se alcanzó una precisión de 95.5 porciento; esta será nuestra *baseline* en el *performance*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojUHiSd4T9-0"
      },
      "source": [
        "## 3. Feature Extraction Approach to Data Preparation\n",
        "\n",
        "Puesto que las variables de entrada son numéricas, se utilizará un rango de transformaciones para cambiar su escala, como *MinMaxScaler, StandardScaler* y *RobustScaler*, así como transformaciones para encadenar la distribución de las variables de entrada como *QuantileTransformer* y *KBinsDiscretizer*. Finalmente, se utilizarán también transformaciones para remover dependencias lineales entre las variables de entrada como *PCA* y *TruncatedSVD*.\n",
        "\n",
        "La clase *FeatureUnion* se puede usar para definir una lista de transformaciones para realizar y luego agregar (unir) sus resultados. Esto crea un nuevo *dataset* que posee un vasto número de columnas.\n",
        "\n",
        "Luego, se puede crear un *Pipeline* con el *FeatureUnion* como el primer paso y el modelo de regresión logística como el último paso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yy2LpKOSrFr",
        "outputId": "a07ecf8f-9189-4ae9-984b-0e6da00e20fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# data preparation as feature engineering for wine dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "# load the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
        "df = read_csv(url, header=None)\n",
        "data = df.values\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# minimally prepare dataset\n",
        "X = X.astype('float')\n",
        "y = LabelEncoder().fit_transform(y.astype('str'))\n",
        "# transforms for the feature union\n",
        "transforms = list()\n",
        "transforms.append(('mms', MinMaxScaler()))\n",
        "transforms.append(('ss', StandardScaler()))\n",
        "transforms.append(('rs', RobustScaler()))\n",
        "transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
        "transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
        "transforms.append(('pca', PCA(n_components=7)))\n",
        "transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
        "# create the feature union\n",
        "fu = FeatureUnion(transforms)\n",
        "# define the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "# define the pipeline\n",
        "steps = list()\n",
        "steps.append(('fu', fu))\n",
        "steps.append(('m', model))\n",
        "pipeline = Pipeline(steps=steps)\n",
        "# define the cross-validation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.968 (0.037)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sf43EIeU0x_"
      },
      "source": [
        "En este caso, se alcanzó un rendimiento de 96.8 porciento, mejor que el *baseline*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkmiqFwbVBdG"
      },
      "source": [
        "También, se puede utilizar *feature selection* para reducir las aproximadamente 80 *extracted features* a un subconjunto de aquellos más relevantes al modelo. Además de reducir la complejidad del modelo, también puede resultar en una mejora en el rendimiento al remover información irrelevante o redundante.\n",
        "\n",
        "En este caso, se utilizará la **Recursive Feature Elimination (RFE)** para elegir los 15 *features* más relevantes. Luego, se puede agregar el RFE al *pipeline*, después del *FeatureUnion* y antes del modelo de regresión logística."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Iyee13VsGY",
        "outputId": "1dd82609-a168-47a4-8d9f-15cbc81084db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# data preparation as feature engineering with feature selection for wine dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "# load the dataset\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/wine.csv'\n",
        "df = read_csv(url, header=None)\n",
        "data = df.values\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "# minimally prepare dataset\n",
        "X = X.astype('float')\n",
        "y = LabelEncoder().fit_transform(y.astype('str'))\n",
        "# transforms for the feature union\n",
        "transforms = list()\n",
        "transforms.append(('mms', MinMaxScaler()))\n",
        "transforms.append(('ss', StandardScaler()))\n",
        "transforms.append(('rs', RobustScaler()))\n",
        "transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
        "transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
        "transforms.append(('pca', PCA(n_components=7)))\n",
        "transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
        "# create the feature union\n",
        "fu = FeatureUnion(transforms)\n",
        "# define the feature selection\n",
        "rfe = RFE(estimator=LogisticRegression(solver='liblinear'), n_features_to_select=15)\n",
        "# define the model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "# define the pipeline\n",
        "steps = list()\n",
        "steps.append(('fu', fu))\n",
        "steps.append(('rfe', rfe))\n",
        "steps.append(('m', model))\n",
        "pipeline = Pipeline(steps=steps)\n",
        "# define the cross-validation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate model\n",
        "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.989 (0.022)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq4qIwY8V3Om"
      },
      "source": [
        "## ¿Qué aprendí?\n",
        "\n",
        "La forma de presentar los conceptos, en un *pipeline*, me parece que funciona muy bien con lo que se quiere obtener: una serie de pasos para navegar los datos sin tener que gastar demasiado tiempo o sin necesitar mucha experiencia. Creo que esto es particularmente útil cuando no se sabe cómo empezar a procesar los datos, pues puede ofrecer, como mínimo, impresiones iniciales sobre cuáles *features* conservar.\n",
        "\n",
        "También, aprendí cómo funciona el RFE, que había sido mencionado en tutoriales anteriores. Me parece interesante cómo se pueden elegir hiperparámetros (por ejemplo, seleccionar los *K* features más importantes del *dataset*) para encontrar cuál punto genera los mejores resultados. Aunado a lo anterior, me gustó aprender el concepto de *baseline performance* que, aunque tenía esta idea intuitiva, no conocía la definición técnica para ella.\n",
        "\n",
        "## ¿Qué me genera dudas?\n",
        "\n",
        "Me interesa conocer cuáles técnicas, si las hay, se usan en conjunto o están relacionadas a *Recursive Feature Elimination*. Ha aparecido en varios tutoriales y parecer ser una técnica muy importante en la preparación de los datos."
      ]
    }
  ]
}